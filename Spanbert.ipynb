{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ebsz4Jwl4wF-","outputId":"913011b1-7879-4084-b9d4-64579948d00a","executionInfo":{"status":"ok","timestamp":1650811362520,"user_tz":-330,"elapsed":3250,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3e-Y4bh5TSG","outputId":"5f36395f-593d-4c3d-a8f9-534d7979978c","executionInfo":{"status":"ok","timestamp":1650811370457,"user_tz":-330,"elapsed":7943,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TKwIJhdvMS07"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cp9hK3KXD_Rn","outputId":"80700b16-2ea7-406c-9683-99e6cd8a13e0","executionInfo":{"status":"ok","timestamp":1650811370458,"user_tz":-330,"elapsed":9,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}],"source":["import matplotlib.pyplot as plt\n","import os\n","import re\n","import string\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from transformers import BertTokenizer, TFBertModel, BertConfig, BertTokenizerFast \n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7SwL2FRiMR_y"},"outputs":[],"source":["data = pd.read_csv(\"/content/drive/My Drive/tamil_data_complete.tsv\",sep=\"\\t\")\n","test = pd.read_csv(\"/content/drive/My Drive/test_data_final.tsv\",sep=\"\\t\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"irdSYFgwMjXi","outputId":"c45d7621-3af6-447f-98a7-29062845481b","executionInfo":{"status":"ok","timestamp":1650811379087,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               spans  \\\n","0  Correct. Enga apa military da oodi vilaiyada s...   \n","1  Dei Rajini pavam da ne varaven poraven ellam k...   \n","2  Dey dey deyyy,, loosu pasangala,, munna pinna ...   \n","3  Intha maari comments ku like kekuravangala ind...   \n","4  250 k likes ineram sila arivuketta pundaika it...   \n","\n","                                                text  \n","0  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 4...  \n","1  [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 3...  \n","2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n","3  [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5...  \n","4  [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...  "],"text/html":["\n","  <div id=\"df-b28cdd71-f2be-4f47-8b28-6705b013ff05\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>spans</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Correct. Enga apa military da oodi vilaiyada s...</td>\n","      <td>[30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 4...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dei Rajini pavam da ne varaven poraven ellam k...</td>\n","      <td>[23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Dey dey deyyy,, loosu pasangala,, munna pinna ...</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Intha maari comments ku like kekuravangala ind...</td>\n","      <td>[42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>250 k likes ineram sila arivuketta pundaika it...</td>\n","      <td>[24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b28cdd71-f2be-4f47-8b28-6705b013ff05')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b28cdd71-f2be-4f47-8b28-6705b013ff05 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b28cdd71-f2be-4f47-8b28-6705b013ff05');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mxl2-OFGMvXX"},"outputs":[],"source":["# Span BERT\n","# 200, 300 and 600\n","max_len = 500\n","\n","tokenizer = BertTokenizerFast.from_pretrained(\"SpanBERT/spanbert-base-cased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CzhN0tBBOZZr"},"outputs":[],"source":["# Evaluation metric\n","\n","import sys\n","import os\n","import os.path\n","from scipy.stats import sem\n","import numpy as np\n","from ast import literal_eval\n","\n","def f1(predictions, gold):\n","    \"\"\"\n","    F1 (a.k.a. DICE) operating on two lists of offsets (e.g., character).\n","    >>> assert f1([0, 1, 4, 5], [0, 1, 6]) == 0.5714285714285714\n","    :param predictions: a list of predicted offsets\n","    :param gold: a list of offsets serving as the ground truth\n","    :return: a score between 0 and 1\n","    \"\"\"\n","    if len(gold) == 0:\n","        return 1. if len(predictions) == 0 else 0.\n","    if len(predictions) == 0:\n","        return 0.\n","    predictions_set = set(predictions)\n","    gold_set = set(gold)\n","    nom = 2 * len(predictions_set.intersection(gold_set))\n","    denom = len(predictions_set) + len(gold_set)\n","    return float(nom)/float(denom)\n","\n","\n","def evaluate(pred, gold):\n","    \"\"\"\n","    Based on https://github.com/felipebravom/EmoInt/blob/master/codalab/scoring_program/evaluation.py\n","    :param pred: file with predictions\n","    :param gold: file with ground truth\n","    :return:\n","    \"\"\"\n","    # # read the predictions\n","    # pred_lines = pred.readlines()\n","    # # read the ground truth\n","    # gold_lines = gold.readlines()\n","\n","    pred_lines = pred\n","    gold_lines = gold\n","\n","    # only when the same number of lines exists\n","    if (len(pred_lines) == len(gold_lines)):\n","        data_dic = {}\n","        for n, line in enumerate(gold_lines):\n","            parts = line.split('\\t')\n","            if len(parts) == 2:\n","                data_dic[int(parts[0])] = [literal_eval(parts[1])]\n","            else:\n","                raise ValueError('Format problem for gold line %d.', n)\n","\n","        for n, line in enumerate(pred_lines):\n","            parts = line.split('\\t')\n","            if len(parts) == 2:\n","                if int(parts[0]) in data_dic:\n","                    try:\n","                        data_dic[int(parts[0])].append(literal_eval(parts[1]))\n","                    except ValueError:\n","                        # Invalid predictions are replaced by a default value\n","                        data_dic[int(parts[0])].append([])\n","                else:\n","                    raise ValueError('Invalid text id for pred line %d.', n)\n","            else:\n","                raise ValueError('Format problem for pred line %d.', n)\n","\n","        # lists storing gold and prediction scores\n","        scores = []\n","        for id in data_dic:\n","            if len(data_dic[id]) == 2:\n","                gold_spans = data_dic[id][0]\n","                pred_spans = data_dic[id][1]\n","                scores.append(f1(pred_spans, gold_spans))\n","            else:\n","                sys.exit('Repeated id in test data.')\n","\n","        return (np.mean(scores), sem(scores))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zWqZhf_c-ub"},"outputs":[],"source":["## To retrive the toxic words from the given input file\n","\n","def span_retrived(text_data, spans):\n","    token_labels = []\n","\n","    for i in range(0, len(text_data)):\n","        token_labels.append(retrieve_word_from_span(spans[i], text_data[i]))\n","    \n","    return token_labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VpVqflF_c4Jv"},"outputs":[],"source":["## for retriving toxic word for every sample\n","\n","def retrieve_word_from_span(lst_span, text):\n","    i = 0\n","    token = []\n","    a = 0\n","\n","    word = []\n","\n","    while (i < (len(lst_span) - 1)):\n","        if (lst_span[i] != (lst_span[i+1]-1)):\n","            token.append(lst_span[a:(i+1)])\n","            a = i + 1\n","        elif i == (len(lst_span) - 2):\n","            token.append(lst_span[a:i+2])\n","\n","        i = i + 1\n","\n","    for t in token:\n","        word.append(text[t[0]:(t[len(t)-1])+1])\n","\n","    return word\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gAAd3RBtgF6w"},"outputs":[],"source":["def span_convert(text_data, spans):\n","    MAX_LEN = 200\n","    token_labels = []\n","\n","    for i in range(0, len(text_data)):\n","        token_labels.append(retrieve_word_from_span(spans[i], text_data[i]))\n","\n","    lst_seq = []\n","    for i in range(0, len(text_data)):\n","        # token = tknzr.tokenize(text_data[i])\n","        token = custom_tokenizer(text_data[i])\n","        if len(token) > MAX_LEN:\n","            MAX_LEN = len(token)\n","            \n","        seq = np.zeros(len(token), dtype=int)\n","        for j in range(0, len(token)):\n","            for t in token_labels[i]:\n","                # if token[j] in tknzr.tokenize(t):\n","                if token[j] in custom_tokenizer(t):\n","                    seq[j] = 1\n","        lst_seq.append(seq)     \n","\n","    return (token_labels, lst_seq)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aoCp65v1hvfZ"},"outputs":[],"source":["def custom_tokenizer(text_data):\n","    return tokenizer.tokenize(text_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIOewRj4jEjq"},"outputs":[],"source":["from ast import literal_eval\n","\n","spans = data['text'].apply(literal_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YP_X4C-tc5Z1"},"outputs":[],"source":["data['token'], data['seq'] = span_convert(data['spans'].values, spans)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"8mdQF_w1dLV4","outputId":"b973d305-43b9-4f55-cbf0-cc8a4fc3a280","executionInfo":{"status":"ok","timestamp":1650811722328,"user_tz":-330,"elapsed":522,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               spans  \\\n","0  Correct. Enga apa military da oodi vilaiyada s...   \n","1  Dei Rajini pavam da ne varaven poraven ellam k...   \n","2  Dey dey deyyy,, loosu pasangala,, munna pinna ...   \n","3  Intha maari comments ku like kekuravangala ind...   \n","4  250 k likes ineram sila arivuketta pundaika it...   \n","\n","                                                text  \\\n","0  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 4...   \n","1  [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 3...   \n","2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n","3  [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5...   \n","4  [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...   \n","\n","                                               token  \\\n","0               [oodi vilaiyada solli tharuvaaaayaa]   \n","1  [varaven poraven ellam karithuppatha koraiya p...   \n","2  [Dey dey deyyy,, loosu pasangala,,  pathruking...   \n","3                 [ india va vittu veliya annupanum]   \n","4               [arivuketta pundaika ithku karanam ]   \n","\n","                                                 seq  \n","0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...  \n","1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...  \n","2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n","3  [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, ...  \n","4  [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...  "],"text/html":["\n","  <div id=\"df-0236a84c-3ed3-47b7-b6e7-d385ae69e34d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>spans</th>\n","      <th>text</th>\n","      <th>token</th>\n","      <th>seq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Correct. Enga apa military da oodi vilaiyada s...</td>\n","      <td>[30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 4...</td>\n","      <td>[oodi vilaiyada solli tharuvaaaayaa]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dei Rajini pavam da ne varaven poraven ellam k...</td>\n","      <td>[23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 3...</td>\n","      <td>[varaven poraven ellam karithuppatha koraiya p...</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Dey dey deyyy,, loosu pasangala,, munna pinna ...</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n","      <td>[Dey dey deyyy,, loosu pasangala,,  pathruking...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Intha maari comments ku like kekuravangala ind...</td>\n","      <td>[42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5...</td>\n","      <td>[ india va vittu veliya annupanum]</td>\n","      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>250 k likes ineram sila arivuketta pundaika it...</td>\n","      <td>[24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...</td>\n","      <td>[arivuketta pundaika ithku karanam ]</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0236a84c-3ed3-47b7-b6e7-d385ae69e34d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0236a84c-3ed3-47b7-b6e7-d385ae69e34d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0236a84c-3ed3-47b7-b6e7-d385ae69e34d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTBdUSCRcDA7"},"outputs":[],"source":["# start index, end index\n","# selected_text -- tokenized text\n","\n","# Fun - preprossin\n","# text = Correct. Enga apa military da oodi vilaiyada s\n","# start_char_index = 30\n","# selected text = oodi vilaiyada solli tharuvaaaayaa - toxic words\n","# all_answers = predicted text will be saved\n","\n","class TrainTweetExample:\n","    def __init__(self,  text, start_char_idx, selected_text, all_answers):\n","        # self.sentiment = sentiment\n","        self.text = text\n","        self.start_char_idx = start_char_idx\n","        self.selected_text = selected_text\n","        self.all_answers = all_answers\n","        self.skip = False\n","\n","    def preprocess(self):\n","        text = self.text\n","        # sentiment = self.sentiment\n","        selected_text = self.selected_text\n","        start_char_idx = self.start_char_idx\n","\n","        # Clean text, sentiment, and answer\n","        # sentiment = \" \".join(str(sentiment).split())\n","        text = \" \".join(str(text).split())\n","        answer = \" \".join(str(selected_text).split())\n","\n","        # Find end character index of answer in text\n","        end_char_idx = start_char_idx + len(answer)\n","        if end_char_idx >= len(text):\n","            self.skip = True\n","            return\n","\n","        # Mark the character indexes in text that are in answer\n","        is_char_in_ans = [0] * len(text)\n","        for idx in range(start_char_idx, end_char_idx):\n","            is_char_in_ans[idx] = 1\n","\n","        # Tokenize text\n","        tokenized_text = tokenizer.encode_plus(text, return_offsets_mapping=True, max_length = max_len)\n","\n","        # Find tokens that were created from answer characters\n","        ans_token_idx = []\n","        for idx, (start, end) in enumerate(tokenized_text.offset_mapping):\n","            if sum(is_char_in_ans[start:end]) > 0:\n","                ans_token_idx.append(idx)\n","\n","        if len(ans_token_idx) == 0:\n","            self.skip = True\n","            return\n","\n","        # Find start and end token index for tokens from answer\n","        start_token_idx = ans_token_idx[0]\n","        end_token_idx = ans_token_idx[-1]\n","\n","        # Tokenize sentiment\n","        # tokenized_sentiment = tokenizer.encode_plus(sentiment, return_offsets_mapping=True, max_length = max_len)\n","\n","        # Create inputs\n","        input_ids = tokenized_text.input_ids \n","        token_type_ids = [0] * len(tokenized_text.input_ids)\n","        attention_mask = [1] * len(input_ids)\n","\n","        # Pad and create attention masks.\n","        # Skip if truncation is needed\n","        padding_length = max_len - len(input_ids)\n","        if padding_length > 0:  # pad\n","            input_ids = input_ids + ([0] * padding_length)\n","            attention_mask = attention_mask + ([0] * padding_length)\n","            token_type_ids = token_type_ids + ([0] * padding_length)\n","        elif padding_length < 0:  # skip\n","            self.skip = True\n","            return\n","\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_mask = attention_mask\n","        self.start_token_idx = start_token_idx\n","        self.end_token_idx = end_token_idx\n","        self.context_token_to_char = tokenized_text.offset_mapping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YrmTvJDncDMU"},"outputs":[],"source":["## this function will created our dataset which will be input to the model . The object of class TrainTweet Examples is used to create dataset.\n","\n","def create_tweet_examples(data):\n","    tweet_examples = []\n","    all_answers = data.token.values\n","    count = 0\n","    for index, row in data.iterrows():\n","        # sentiment = row['sentiment']\n","        text = row['spans']\n","        selected_text = row['token']\n","        # print(row.text)\n","        start_char_idx = row.spans.index(row.token[0])\n","        tweet_eg = TrainTweetExample(\n","              text, start_char_idx, selected_text, all_answers\n","        )\n","        tweet_eg.preprocess()\n","        tweet_examples.append(tweet_eg)\n","        # except: ## keep track of the number that can't be tokenized/processed\n","        #     count += 1 \n","    # print(\"Couldn't process\",count,\"points\")\n","    return tweet_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SNDuaP4dkMfQ"},"outputs":[],"source":["# The ouput generated by the create_tweet_examples will be input to given function.\n","\n","# x = input_ids, token_type_ids and attention_mask which are defined in Train_Tweet_example\n","# y = start_token_idx, end_token_idx\n","\n","# input_ids = ids created by the tokanizer\n","# token_type_ids = give 0 attention to this non toxic words\n","# attention_mast = give 1 attention to toxic words\n","\n","\n","def create_inputs_targets(tweet_examples):\n","    dataset_dict = {\n","        \"input_ids\": [],\n","        \"token_type_ids\": [],\n","        \"attention_mask\": [],\n","        \"start_token_idx\": [],\n","        \"end_token_idx\": [],\n","    }\n","    for item in tweet_examples:\n","        if item.skip == False:\n","            for key in dataset_dict:\n","                dataset_dict[key].append(getattr(item, key))\n","    for key in dataset_dict:\n","        dataset_dict[key] = np.array(dataset_dict[key])\n","    print(dataset_dict[\"input_ids\"])\n","    x = [\n","        dataset_dict[\"input_ids\"],\n","        dataset_dict[\"token_type_ids\"],\n","        dataset_dict[\"attention_mask\"],\n","    ]\n","    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n","    return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqwqJZfoL9vc"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train, validation = train_test_split(data, test_size = 0.1,random_state=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5-mGjSacDWF","outputId":"3d2cb940-9140-4c17-eff0-102fc95d3364","executionInfo":{"status":"ok","timestamp":1650811726075,"user_tz":-330,"elapsed":1815,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["[[  101 16664  1161 ...     0     0     0]\n"," [  101   188  2093 ...     0     0     0]\n"," [  101 23015  1161 ...     0     0     0]\n"," ...\n"," [  101  5358  1182 ...     0     0     0]\n"," [  101   180  4867 ...     0     0     0]\n"," [  101  4035  1605 ...     0     0     0]]\n","4334 training points created.\n"]}],"source":["\n","# = y = [30,40] starting = 30,ending = 40\n","train_tweet_examples = create_tweet_examples(train)\n","x_train, y_train = create_inputs_targets(train_tweet_examples)\n","print(f\"{len(train_tweet_examples)} training points created.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nVMbzS5ecHMK","outputId":"c89147d9-ea3b-451e-be16-f68fa84363cb","executionInfo":{"status":"ok","timestamp":1650811726077,"user_tz":-330,"elapsed":19,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, 2312, 500)"]},"metadata":{},"execution_count":38}],"source":["np.array(x_train).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaUDuTDNM6lQ"},"outputs":[],"source":["def create_model():\n","\n","    PATH = 'SpanBERT/spanbert-base-cased'\n","    encoder = TFBertModel.from_pretrained(PATH, from_pt = True)\n","    \n","## QA Model\n","    input_ids = layers.Input(shape=(max_len ,), dtype=tf.int32)\n","    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    embedding = encoder(\n","         input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n","    )[0]\n","    \n","\n","    start_logits = layers.Dropout(0.3)(embedding)\n","    start_logits = layers.Conv1D(128,2,padding='same')(start_logits)\n","    start_logits = layers.LeakyReLU()(start_logits)\n","    start_logits = layers.Conv1D(64,2,padding='same')(start_logits)\n","    start_logits = layers.Dense(1, name=\"start_logit\")(start_logits)\n","    start_logits = layers.Flatten()(start_logits)\n","\n","    end_logits = layers.Dropout(0.3)(embedding)\n","    end_logits = layers.Conv1D(128,2,padding='same')(end_logits)\n","    end_logits = layers.LeakyReLU()(end_logits)\n","    end_logits = layers.Conv1D(64,2,padding='same')(end_logits)\n","    end_logits = layers.Dense(1, name=\"end_logit\")(end_logits)\n","    end_logits = layers.Flatten()(end_logits)\n","\n","    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n","    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n","\n","    model = keras.Model(\n","        inputs=[input_ids, token_type_ids, attention_mask],\n","        outputs=[start_probs, end_probs],\n","    )\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    optimizer = keras.optimizers.Adam(lr=5e-5)\n","    model.compile(optimizer=optimizer, loss=[loss, loss],metrics=[\"accuracy\"])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["69312df241114a24b23d503527da3e9f","6f08a8e95d6b41c38a23e2a8603ad187","86c812cecc98448b8ae6a98a5f432838","95b1a700721e44aeb75517a07a782758","79c88a31292e4676be03bc897060dc5e","3a266945f13349be8189f9ae36bf7f16","444f90feaf594130a4fc3dc3c28358a8","474aa0db131a47c0bb901e0ce85f7def","90f73ccaee6f42889ee896bbd7005170","577538b749554f5c81a126b91883cf63","f27f04bf34f94ae1af0ebea5e4c29f69"]},"id":"Mjtf2aqdQPSz","outputId":"1a1059aa-20d1-4c22-f028-7bf8c151cd45","executionInfo":{"status":"ok","timestamp":1650811747609,"user_tz":-330,"elapsed":21543,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/205M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69312df241114a24b23d503527da3e9f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}],"source":["model = create_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_qnhHN5gQTT9","outputId":"9853ed6b-a829-4e32-fbab-cc4e32b2f3d6","executionInfo":{"status":"ok","timestamp":1650811747610,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 500)]        0           []                               \n","                                                                                                  \n"," input_3 (InputLayer)           [(None, 500)]        0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 500)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_1[0][0]',                \n","                                thPoolingAndCrossAt               'input_3[0][0]',                \n","                                tentions(last_hidde               'input_2[0][0]']                \n","                                n_state=(None, 500,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 500, 768)     0           ['tf_bert_model[0][0]']          \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, 500, 768)     0           ['tf_bert_model[0][0]']          \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 500, 128)     196736      ['dropout_37[0][0]']             \n","                                                                                                  \n"," conv1d_2 (Conv1D)              (None, 500, 128)     196736      ['dropout_38[0][0]']             \n","                                                                                                  \n"," leaky_re_lu (LeakyReLU)        (None, 500, 128)     0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," leaky_re_lu_1 (LeakyReLU)      (None, 500, 128)     0           ['conv1d_2[0][0]']               \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 500, 64)      16448       ['leaky_re_lu[0][0]']            \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 500, 64)      16448       ['leaky_re_lu_1[0][0]']          \n","                                                                                                  \n"," start_logit (Dense)            (None, 500, 1)       65          ['conv1d_1[0][0]']               \n","                                                                                                  \n"," end_logit (Dense)              (None, 500, 1)       65          ['conv1d_3[0][0]']               \n","                                                                                                  \n"," flatten (Flatten)              (None, 500)          0           ['start_logit[0][0]']            \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 500)          0           ['end_logit[0][0]']              \n","                                                                                                  \n"," activation (Activation)        (None, 500)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," activation_1 (Activation)      (None, 500)          0           ['flatten_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 108,736,770\n","Trainable params: 108,736,770\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycR_ks6Vxfoo"},"outputs":[],"source":["batch_size = 8\n","div = len(x_train[0]) - (len(x_train[0]) % batch_size)\n","x = list(np.array(x_train)[:,:div]) ## inputs must be divisible by batch size \n","y = list(np.array(y_train)[:,:div])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvF7oqlXQnlA","outputId":"e3ffc319-8d67-4611-d21c-68d7288c79bf","executionInfo":{"status":"ok","timestamp":1650812949230,"user_tz":-330,"elapsed":536772,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["289/289 [==============================] - 536s 2s/step - loss: 4.3269 - activation_loss: 1.6745 - activation_1_loss: 2.6525 - activation_accuracy: 0.4567 - activation_1_accuracy: 0.2522\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f2063cfb590>"]},"metadata":{},"execution_count":44}],"source":["model.fit(\n","    list(np.array(x)),\n","    list(np.array(y)),\n","    epochs=1,\n","    batch_size=batch_size,\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3HhCsfrRtgX","outputId":"7d3d313b-ac99-4ee0-8f01-427d133d7229","executionInfo":{"status":"ok","timestamp":1650812956921,"user_tz":-330,"elapsed":886,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[[  101   187 12487 ...     0     0     0]\n"," [  101  4035  1605 ...     0     0     0]\n"," [  101  1126  7939 ...     0     0     0]\n"," ...\n"," [  101   187 22558 ...     0     0     0]\n"," [  101   185  3715 ...     0     0     0]\n"," [  101   178 20564 ...     0     0     0]]\n","482 evaluation points created.\n"]}],"source":["eval_tweet_examples = create_tweet_examples(validation)\n","x_eval, y_eval = create_inputs_targets(eval_tweet_examples)\n","print(f\"{len(eval_tweet_examples)} evaluation points created.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6_p_Bf_JRy_"},"outputs":[],"source":["## Prediction of the test data\n","\n","pred = model.predict(x_eval)\n","\n","pred_start, pred_end = pred\n","count = 0\n","\n","pred_text = []\n","validation['prediction'] = np.zeros(len(validation.spans.values))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFQhW096RPDW","outputId":"a7f5901e-2bbc-4866-e673-6f729f9a1e85","executionInfo":{"status":"ok","timestamp":1650812984136,"user_tz":-330,"elapsed":31,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}],"source":["## Extracting the toxic words from the prediction\n","\n","validation['start']=np.zeros(len(validation.spans.values))\n","validation['end']=np.zeros(len(validation.spans.values))\n","\n","\n","listsk = list(validation.index)\n","for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n","    tweet_eg = eval_tweet_examples[idx]\n","    if (tweet_eg.skip == True):\n","        pred_text.append(\"\")\n","    else: \n","        offsets = tweet_eg.context_token_to_char\n","        start = np.argmax(start)\n","        end = np.argmax(end)\n","        if start >= len(offsets):\n","            continue\n","        pred_char_start = offsets[start][0]\n","        if end < len(offsets):\n","            pred_char_end = offsets[end][1]\n","            pred_ans = tweet_eg.text[pred_char_start:pred_char_end + 1]\n","        else:\n","            pred_ans = tweet_eg.text[pred_char_start:]\n","\n","        validation['start'][listsk[idx]] = pred_char_start\n","        validation['end'][listsk[idx]] = pred_char_end\n","\n","        # normalized_pred_ans = normalize_text(pred_ans)\n","        #print(normalized_pred_ans)\n","        pred_text.append(pred_ans)\n","        # print(pred_ans)\n","        validation['prediction'][listsk[idx]]= pred_ans\n","\n","\n","# for x in list(validation.index):\n","#   validation['start'][x] = validation['spans'][x].find(str(validation['prediction'][x]))\n","#   validation['end'][x] = start+len(str(validation['prediction'][x]))\n","\n","\n","## The required output i.e spans of the toxic words\n","\n","lists = list()\n","for x in list(validation.index):\n","  a = np.array(range(int(validation['start'][x]),int(validation['end'][x])+1))\n","  lists.append(a.astype('int'))\n","\n","validation['spans_predict'] = lists\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zYSnjvGXnJwQ"},"outputs":[],"source":["validation['text'] = validation['text'].apply(literal_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"eixlnh2f8-eJ","outputId":"e6a04844-995f-4d8b-edf0-0938ee38a2b8","executionInfo":{"status":"ok","timestamp":1650812984137,"user_tz":-330,"elapsed":10,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  spans  \\\n","1309  Rajini Ku sema mokka kuduthurukanga nice comed...   \n","4574            Ethuku 63k dislike apdi enna pathutinga   \n","422                           Enna da saw movie copy ah   \n","97    Enna dhan kaalam maranalum andha sadhi veri ad...   \n","1835        Final ah thalaivara vachu senjitingaleh dah   \n","\n","                                                   text  \\\n","1309  [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2...   \n","4574  [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3...   \n","422        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]   \n","97    [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 5...   \n","1835  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 3...   \n","\n","                                                  token  \\\n","1309                            [mokka kuduthurukanga ]   \n","4574                             [apdi enna pathutinga]   \n","422                                       [movie copy ]   \n","97    [adanga matrangu , sc vela bc Vella illa Enna ...   \n","1835                            [vachu senjitingaleh d]   \n","\n","                                                    seq  \\\n","1309  [0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n","4574         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]   \n","422                               [0, 0, 0, 0, 1, 1, 0]   \n","97    [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n","1835   [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]   \n","\n","                      prediction  start   end  \\\n","1309  mokka kuduthurukanga nice    15.0  40.0   \n","4574                         0.0    0.0   0.0   \n","422                          0.0    0.0   0.0   \n","97                ranalum andha    19.0  32.0   \n","1835                         0.0    0.0   0.0   \n","\n","                                          spans_predict  \n","1309  [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2...  \n","4574                                                [0]  \n","422                                                 [0]  \n","97    [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3...  \n","1835                                                [0]  "],"text/html":["\n","  <div id=\"df-bfd0490d-2e61-45a6-8847-5cd92e7b6673\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>spans</th>\n","      <th>text</th>\n","      <th>token</th>\n","      <th>seq</th>\n","      <th>prediction</th>\n","      <th>start</th>\n","      <th>end</th>\n","      <th>spans_predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1309</th>\n","      <td>Rajini Ku sema mokka kuduthurukanga nice comed...</td>\n","      <td>[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2...</td>\n","      <td>[mokka kuduthurukanga ]</td>\n","      <td>[0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>mokka kuduthurukanga nice</td>\n","      <td>15.0</td>\n","      <td>40.0</td>\n","      <td>[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2...</td>\n","    </tr>\n","    <tr>\n","      <th>4574</th>\n","      <td>Ethuku 63k dislike apdi enna pathutinga</td>\n","      <td>[19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3...</td>\n","      <td>[apdi enna pathutinga]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>[0]</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>Enna da saw movie copy ah</td>\n","      <td>[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]</td>\n","      <td>[movie copy ]</td>\n","      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>[0]</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>Enna dhan kaalam maranalum andha sadhi veri ad...</td>\n","      <td>[44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 5...</td>\n","      <td>[adanga matrangu , sc vela bc Vella illa Enna ...</td>\n","      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n","      <td>ranalum andha</td>\n","      <td>19.0</td>\n","      <td>32.0</td>\n","      <td>[19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>1835</th>\n","      <td>Final ah thalaivara vachu senjitingaleh dah</td>\n","      <td>[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 3...</td>\n","      <td>[vachu senjitingaleh d]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>[0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfd0490d-2e61-45a6-8847-5cd92e7b6673')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bfd0490d-2e61-45a6-8847-5cd92e7b6673 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bfd0490d-2e61-45a6-8847-5cd92e7b6673');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":49}],"source":["# spans = given sentence\n","# text = spans of toxic words\n","# token = extracted toxic word\n","# prediction = predicted toxic word\n","# start = predicted starting index\n","# end = predicted ending index\n","\n","validation.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmtjbyyHJSBw","outputId":"a353cdb2-3be4-40a8-e441-ec653dc506e6","executionInfo":{"status":"ok","timestamp":1650812984694,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["10.36244180601232\n"]}],"source":["acc = []\n","for i in list(validation.index):\n","    acc.append(f1(np.array(validation['text'][i]), np.array(validation['spans_predict'][i])))\n","\n","print(np.mean(acc)*100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Ac-4boZyra2"},"outputs":[],"source":["class TestTweetExample:\n","    def __init__(self,  text):\n","        # self.sentiment = sentiment\n","        self.text = text\n","        self.skip = False\n","\n","    def preprocess(self):\n","        text = self.text\n","        # sentiment = self.sentiment\n","\n","        # Clean text, answer and sentiment\n","        # sentiment = \" \".join(str(sentiment).split())\n","        text = \" \".join(str(text).split())\n","\n","        # Tokenize text\n","        tokenized_text = tokenizer.encode_plus(text, return_offsets_mapping=True, max_length = max_len)\n","\n","        # Tokenize sentiment\n","        # tokenized_sentiment = tokenizer.encode_plus(sentiment, return_offsets_mapping=True, max_length = max_len)\n","\n","        # Create inputs\n","        input_ids = tokenized_text.input_ids\n","        token_type_ids = [0] * len(tokenized_text.input_ids)\n","        attention_mask = [1] * len(input_ids)\n","\n","        # Pad and create attention masks.\n","        # Skip if truncation is needed\n","        padding_length = max_len - len(input_ids)\n","        if padding_length > 0:  # pad\n","            input_ids = input_ids + ([0] * padding_length)\n","            attention_mask = attention_mask + ([0] * padding_length)\n","            token_type_ids = token_type_ids + ([0] * padding_length)\n","        elif padding_length < 0:  # skip\n","            self.skip = True\n","            return\n","\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_mask = attention_mask\n","        self.text_token_to_char = tokenized_text.offset_mapping\n","        self.start_token_idx = 0\n","        self.end_token_idx = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbVvvQuCyroI"},"outputs":[],"source":["def create_tweet_examples_test(data):\n","    tweet_examples = []\n","    all_answers = None\n","    count = 0\n","    for index, row in data.iterrows():\n","        text = row['text']\n","        selected_text = None\n","\n","        start_char_idx = 0\n","        tweet_eg = TestTweetExample(\n","                text\n","        )\n","        tweet_eg.preprocess()\n","        tweet_examples.append(tweet_eg)\n","    print(\"Couldn't process\",count,\"points\")\n","    return tweet_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMXJ249TyYpF","executionInfo":{"status":"ok","timestamp":1650813000498,"user_tz":-330,"elapsed":450,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}},"outputId":"a9bb9b5d-c5b5-414d-b528-8cedcd9de80b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Couldn't process 0 points\n","[[  101   174  5242 ...     0     0     0]\n"," [  101  8050  6851 ...     0     0     0]\n"," [  101  7688  8556 ...     0     0     0]\n"," ...\n"," [  101  5952 21842 ...     0     0     0]\n"," [  101   180  7903 ...     0     0     0]\n"," [  101  1137 15796 ...     0     0     0]]\n","876 test points created.\n"]}],"source":["test_tweet_examples = create_tweet_examples_test(test)\n","x_test, _ = create_inputs_targets(test_tweet_examples)\n","print(f\"{len(test_tweet_examples)} test points created.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXsYzanfQ6Ar","executionInfo":{"status":"ok","timestamp":1650813065850,"user_tz":-330,"elapsed":65353,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}},"outputId":"2d243709-8b5e-42a4-eb55-441615de878a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 876, 500)"]},"metadata":{},"execution_count":54}],"source":["pred = model.predict(x_test)\n","np.array(pred).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABYWqWbhz2-e","executionInfo":{"status":"ok","timestamp":1650813066483,"user_tz":-330,"elapsed":641,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}},"outputId":"48df8407-9d92-4d41-c11f-bd2a9a7d0e5f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}],"source":["pred_start, pred_end = pred\n","count = 0\n","\n","pred_text = []\n","\n","test['prediction'] = np.zeros(len(test.text.values))\n","\n","for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n","    tweet_eg = test_tweet_examples[idx]\n","    if (tweet_eg.skip == True):\n","        pred_text.append(\"\")\n","    else: \n","        offsets = tweet_eg.text_token_to_char\n","        start = np.argmax(start)\n","        end = np.argmax(end)\n","        if start >= len(offsets):\n","            continue\n","        pred_char_start = offsets[start][0]\n","        if end < len(offsets):\n","            pred_char_end = offsets[end][1]\n","            pred_ans = tweet_eg.text[pred_char_start:pred_char_end + 1]\n","        else:\n","            pred_ans = tweet_eg.text[pred_char_start:]\n","\n","        # normalized_pred_ans = normalize_text(pred_ans)\n","        #print(normalized_pred_ans)\n","        pred_text.append(pred_ans)\n","        test['prediction'][idx] = pred_ans\n","\n","test['start']=np.zeros(len(test.text.values))\n","test['end']=np.zeros(len(test.text.values))\n","\n","for x in range(0,len(test)):\n","  test['start'][x] = test['text'][x].find(test['prediction'][x])\n","  test['end'][x] = start+len(test['prediction'][x])\n","\n","\n","\n","lists = list()\n","for x in range(0,len(test)):\n","  a = np.array(range(int(test['start'][x]),int(test['end'][x])+1))\n","  lists.append(a)\n","\n","test['spans_predict'] = lists"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"oazLaAJVzTu-","executionInfo":{"status":"ok","timestamp":1650813077324,"user_tz":-330,"elapsed":353,"user":{"displayName":"Mohit Madhukar More 19MIA1005","userId":"00583940432550358120"}},"outputId":"1c04eddf-56b7-4d21-edca-bc4a0df366c1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text  \\\n","0    Evanukachum pondati kolandhainu sentiment irun...   \n","1        Adei ennada short film la irunthu suturukinga   \n","2    Super dialogue  Oruthar mela visvasam kattrath...   \n","3    Epadiya jathi padam. Ponnu padama edungada. In...   \n","4    Ponnu mella kaivaikuravan Kai mattum illa uyir...   \n","..                                                 ...   \n","871  காலா.காபலி.அசுரன்.பாரியேரும்.பெருமள் வந்த அப்ப...   \n","872               Kekka bekka short film mathri irukey   \n","873  Bayangaram... Trailerey ippadina appa Padam en...   \n","874  komali rasini vesam pottu tamil ilichavayangal...   \n","875  Oruththar Mela katra viswasaththukku maththava...   \n","\n","                                            prediction  start    end  \\\n","0    pondati kolandhainu sentiment irundha , apdiya...   12.0  110.0   \n","1             Adei ennada short film la irunthu suturu    0.0   63.0   \n","2        visvasam kattrathukkaga innoruthavarai asinga   28.0   69.0   \n","3    Ponnu padama edungada. India vallarasu agidun....   21.0   90.0   \n","4                                 Kai mattum illa uyir   26.0   43.0   \n","..                                                 ...    ...    ...   \n","871                             punda passagala ungalu   99.0   45.0   \n","872                       Kekka bekka short film mathr    0.0   51.0   \n","873  Bayangaram... Trailerey ippadina appa Padam en...    0.0   91.0   \n","874  komali rasini vesam pottu tamil ilichavayangal...    0.0   77.0   \n","875                      asinga paduththuruinge ungala   56.0   52.0   \n","\n","                                         spans_predict  \n","0    [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 2...  \n","1    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n","2    [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 3...  \n","3    [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 3...  \n","4    [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 3...  \n","..                                                 ...  \n","871                                                 []  \n","872  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n","873  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n","874  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n","875                                                 []  \n","\n","[876 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-32c515d7-fee5-40b3-889a-649a350ca3ed\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>prediction</th>\n","      <th>start</th>\n","      <th>end</th>\n","      <th>spans_predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Evanukachum pondati kolandhainu sentiment irun...</td>\n","      <td>pondati kolandhainu sentiment irundha , apdiya...</td>\n","      <td>12.0</td>\n","      <td>110.0</td>\n","      <td>[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 2...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Adei ennada short film la irunthu suturukinga</td>\n","      <td>Adei ennada short film la irunthu suturu</td>\n","      <td>0.0</td>\n","      <td>63.0</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Super dialogue  Oruthar mela visvasam kattrath...</td>\n","      <td>visvasam kattrathukkaga innoruthavarai asinga</td>\n","      <td>28.0</td>\n","      <td>69.0</td>\n","      <td>[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Epadiya jathi padam. Ponnu padama edungada. In...</td>\n","      <td>Ponnu padama edungada. India vallarasu agidun....</td>\n","      <td>21.0</td>\n","      <td>90.0</td>\n","      <td>[21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ponnu mella kaivaikuravan Kai mattum illa uyir...</td>\n","      <td>Kai mattum illa uyir</td>\n","      <td>26.0</td>\n","      <td>43.0</td>\n","      <td>[26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>871</th>\n","      <td>காலா.காபலி.அசுரன்.பாரியேரும்.பெருமள் வந்த அப்ப...</td>\n","      <td>punda passagala ungalu</td>\n","      <td>99.0</td>\n","      <td>45.0</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>872</th>\n","      <td>Kekka bekka short film mathri irukey</td>\n","      <td>Kekka bekka short film mathr</td>\n","      <td>0.0</td>\n","      <td>51.0</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n","    </tr>\n","    <tr>\n","      <th>873</th>\n","      <td>Bayangaram... Trailerey ippadina appa Padam en...</td>\n","      <td>Bayangaram... Trailerey ippadina appa Padam en...</td>\n","      <td>0.0</td>\n","      <td>91.0</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n","    </tr>\n","    <tr>\n","      <th>874</th>\n","      <td>komali rasini vesam pottu tamil ilichavayangal...</td>\n","      <td>komali rasini vesam pottu tamil ilichavayangal...</td>\n","      <td>0.0</td>\n","      <td>77.0</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n","    </tr>\n","    <tr>\n","      <th>875</th>\n","      <td>Oruththar Mela katra viswasaththukku maththava...</td>\n","      <td>asinga paduththuruinge ungala</td>\n","      <td>56.0</td>\n","      <td>52.0</td>\n","      <td>[]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>876 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32c515d7-fee5-40b3-889a-649a350ca3ed')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-32c515d7-fee5-40b3-889a-649a350ca3ed button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-32c515d7-fee5-40b3-889a-649a350ca3ed');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":56}],"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaDSAjW1G3Nm"},"outputs":[],"source":["new_sub = pd.DataFrame({'text': test['text'], 'spans': test['spans_predict']})\n","\n","new_sub.to_csv('drive/My Drive/CODE/SemVal/test_demo_detection.tsv',sep=\"\\t\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBgFhVwlhfnv"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Spanbert.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"69312df241114a24b23d503527da3e9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f08a8e95d6b41c38a23e2a8603ad187","IPY_MODEL_86c812cecc98448b8ae6a98a5f432838","IPY_MODEL_95b1a700721e44aeb75517a07a782758"],"layout":"IPY_MODEL_79c88a31292e4676be03bc897060dc5e"}},"6f08a8e95d6b41c38a23e2a8603ad187":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a266945f13349be8189f9ae36bf7f16","placeholder":"​","style":"IPY_MODEL_444f90feaf594130a4fc3dc3c28358a8","value":"Downloading: 100%"}},"86c812cecc98448b8ae6a98a5f432838":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_474aa0db131a47c0bb901e0ce85f7def","max":215475882,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90f73ccaee6f42889ee896bbd7005170","value":215475882}},"95b1a700721e44aeb75517a07a782758":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_577538b749554f5c81a126b91883cf63","placeholder":"​","style":"IPY_MODEL_f27f04bf34f94ae1af0ebea5e4c29f69","value":" 205M/205M [00:06&lt;00:00, 35.2MB/s]"}},"79c88a31292e4676be03bc897060dc5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a266945f13349be8189f9ae36bf7f16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"444f90feaf594130a4fc3dc3c28358a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"474aa0db131a47c0bb901e0ce85f7def":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90f73ccaee6f42889ee896bbd7005170":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"577538b749554f5c81a126b91883cf63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f27f04bf34f94ae1af0ebea5e4c29f69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}